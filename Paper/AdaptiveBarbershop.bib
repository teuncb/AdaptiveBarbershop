
@book{van_de_craats_fis_1989,
	title = {De fis van Euler. Een nieuwe visie op de muziek van Schubert, Beethoven, Mozart en Bach.},
	publisher = {Aramith Uitgevers},
	author = {Van de Craats, Jan},
	date = {1989},
}

@article{barbershop_harmony_society_contest_2022,
	title = {Contest and Judging Handbook},
	url = {https://www.barbershop.org/contests/contests-judging},
	issue = {July 2022},
	author = {{Barbershop Harmony Society}},
	date = {2022},
	langid = {english},
	file = {CONTEST AND JUDGING HANDBOOK.pdf:D\:\\Lokaal\\Documenten\\Zotero\\storage\\SYUDC5SM\\CONTEST AND JUDGING HANDBOOK.pdf:application/pdf},
}

@article{sethares_adaptive_1994,
	title = {Adaptive tunings for musical scales},
	volume = {96},
	rights = {© 1994 Acoustical Society of America.},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.410471},
	doi = {10.1121/1.410471},
	abstract = {A fixed, octave‐based musical scale cannot remain faithful to the consonant simple integer ratio intervals and simultaneously be modulated to all keys. It is possible to reconcile these competing criteria, however, if the notes of the scale are allowed to vary. This paper presents a method of adjusting the pitches of notes dynamically, an adaptive tuning, that maintains fidelity to a desired set of intervals and can be modulated to any key. The adaptive tuning algorithm changes the pitches of notes in a musical performance so as to maximize consonance, which is calculated based on recent perceptual work. The algorithm can operate in real time, is responsive to the notes played, and can be readily tailored to the timbre (or spectrum) of the sound. This can be viewed as a generalization of the methods of just intonation, but it can operate without specifically musical knowledge such as key and tonal center and is applicable to timbres with nonharmonic spectra as well as the more common harmonic timbres.},
	pages = {10},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Sethares, William A.},
	urldate = {2023-02-13},
	date = {1994-04-05},
	langid = {english},
	note = {Publisher: Acoustical Society of {AmericaASA}},
	file = {Ingediende versie:D\:\\Lokaal\\Documenten\\Zotero\\storage\\64VATPPC\\Sethares - 1998 - Adaptive tunings for musical scales.pdf:application/pdf},
}

@article{devaney_study_2012,
	title = {A study of intonation in three-part singing using the Automatic Music Performance Analysis and Comparison Toolkit ({AMPACT})},
	abstract = {This paper introduces the Automatic Music Performance Analysis and Comparison Toolkit ({AMPACT}), is a {MATLAB} toolkit for accurately aligning monophonic audio to {MIDI} scores as well as extracting and analyzing timing-, pitch-, and dynamics-related performance data from the aligned recordings. This paper also presents the results of an analysis performed with {AMPACT} on an experiment studying intonation in three-part singing. The experiment examines the interval size and drift in four ensembles' performances of a short exercise by Benedetti, which was designed to highlight the conflict between Just Intonation tuning and pitch drift.},
	pages = {511--516},
	journaltitle = {Proceedings of the 13th International Society for Music Information Retrieval Conference, {ISMIR} 2012},
	shortjournal = {Proceedings of the 13th International Society for Music Information Retrieval Conference, {ISMIR} 2012},
	author = {Devaney, Johanna and Mandel, Michael and Fujinaga, Ichiro},
	date = {2012-01-01},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\MVL7Z42L\\Devaney e.a. - 2012 - A study of intonation in three-part singing using .pdf:application/pdf},
}

@misc{mohrlok_hermode_2003,
	title = {The Hermode Tuning System},
	url = {https://sethares.engr.wisc.edu/paperspdf/hermode.pdf},
	author = {Mohrlok, Werner},
	date = {2003},
	file = {Mohrlok - 2003 - The Hermode Tuning System.pdf:D\:\\Lokaal\\Documenten\\Zotero\\storage\\MVIFGIEQ\\Mohrlok - 2003 - The Hermode Tuning System.pdf:application/pdf},
}

@online{volkov_pivotuner_2022,
	title = {Pivotuner},
	url = {https://midi.org/component/zoo/item/pivotuner},
	author = {Volkov, Dmitri},
	urldate = {2023-02-13},
	date = {2022},
	file = {Pivotuner:D\:\\Lokaal\\Documenten\\Zotero\\storage\\CN8EFUGW\\pivotuner.html:text/html},
}

@article{code_grovenmax_2002,
	title = {Groven.Max: An Adaptive Tuning System for {MIDI} Pianos},
	volume = {26},
	issn = {0148-9267},
	url = {https://www.jstor.org/stable/3681456},
	shorttitle = {Groven.Max},
	pages = {50--61},
	number = {2},
	journaltitle = {Computer Music Journal},
	author = {Code, David Løberg},
	urldate = {2023-02-13},
	date = {2002},
	note = {Publisher: The {MIT} Press},
	file = {JSTOR Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\39IUYRW8\\Code - 2002 - Groven.Max An Adaptive Tuning System for MIDI Pia.pdf:application/pdf},
}

@article{garnett_ethics_1999,
	title = {Ethics and aesthetics: the social theory of barbershop harmony},
	volume = {18},
	issn = {1474-0095, 0261-1430},
	url = {https://www.cambridge.org/core/journals/popular-music/article/abs/ethics-and-aesthetics-the-social-theory-of-barbershop-harmony/88DD765DDACCB632A1B5086885B393DE},
	doi = {10.1017/S0261143000008722},
	shorttitle = {Ethics and aesthetics},
	abstract = {Until recently, the world of the British barbershop singer was a self-enclosed community whose existence went largely unrecognised both by musicians involved in other genres and by the public at large. In the last few years this has started to change, chiefly due to the participation of barbershop choruses in the televised competition ‘Sainsbury's Choir of the Year’. Encouraged by the success of Shannon Express in 1994, many other choruses entered the 1996 competition, four of them reaching the televised semi-finals, and two the finals. During this increased exposure, it became apparent that television commentators had little idea of what to make of barbershoppers, indeed regarded them as a peculiar, and perhaps rather trivial, breed of performer. This bafflement is not surprising given the genre's relative paucity of exposure either in the mass media or in the musical and musicological press; the plentiful articles written by barbershoppers about their activity and its meanings are almost exclusively addressed to each other, to sustain the community rather than integrate it into wider musical life. The purpose of this paper, however, is not to follow the theme of these intra-community articles in arguing that barbershop harmony should actually be regarded as a serious and worthy art, or to explain to a bewildered world what this genre is actually about; rather, it aims to explore the way that barbershop singers theorise themselves and their activity to provide a case study in the relationship between social and musical values. That is, I am not writing as an apologist for a hitherto distinctly insular practice, but exploiting that very insularity as a means to pursue a potentially very broad question within a self-limited field of enquiry.},
	pages = {41--61},
	number = {1},
	journaltitle = {Popular Music},
	author = {Garnett, Liz},
	urldate = {2023-02-13},
	date = {1999-01},
	langid = {english},
	note = {Publisher: Cambridge University Press},
}

@book{hagerman_fundamental_1980,
	title = {Fundamental frequency adjustment in barbershop singing},
	publisher = {Citeseer},
	author = {Hagerman, B. and Sundberg, Johan},
	date = {1980},
	file = {Full Text:D\:\\Lokaal\\Documenten\\Zotero\\storage\\IABSFD9Z\\Hagerman en Sundberg - 1980 - Fundamental frequency adjustment in barbershop sin.pdf:application/pdf},
}

@article{mauch_intonation_2014,
	title = {Intonation in unaccompanied singing: Accuracy, drift, and a model of reference pitch memory},
	volume = {136},
	doi = {10.1121/1.4881915},
	shorttitle = {Intonation in unaccompanied singing},
	abstract = {This paper presents a study on intonation and intonation drift in unaccompanied singing, and proposes a simple model of reference pitch memory that accounts for many of the effects observed. Singing experiments were conducted with 24 singers of varying ability under three conditions (Normal, Masked, Imagined). Over the duration of a recording, ∼50 s, a median absolute intonation drift of 11 cents was observed. While smaller than the median note error (19 cents), drift was significant in 22\% of recordings. Drift magnitude did not correlate with other measures of singing accuracy, singing experience, or the presence of conditions tested. Furthermore, it is shown that neither a static intonation memory model nor a memoryless interval-based intonation model can account for the accuracy and drift behavior observed. The proposed causal model provides a better explanation as it treats the reference pitch as a changing latent variable.},
	pages = {401},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Mauch, Matthias and Frieler, Klaus and Dixon, Simon},
	date = {2014-07-01},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\JLKJP852\\Mauch e.a. - 2014 - Intonation in unaccompanied singing Accuracy, dri.pdf:application/pdf},
}

@article{dai_intonation_2019,
	title = {Intonation trajectories within tones in unaccompanied soprano, alto, tenor, bass quartet singing},
	volume = {146},
	doi = {10.1121/1.5120483},
	abstract = {Unlike fixed-pitch instruments, the voice requires careful regulation during each note in order to maintain a steady pitch. Previous studies have investigated aspects of singing performance such as intonation accuracy and pitch drift, treating pitch as fixed within notes, while the pitch trajectory within notes has hardly been investigated. The aim of this paper is to study pitch variation within vocal notes and ascertain what factors influence the various parts of a note. The authors recorded five soprano, alto, tenor, bass quartets singing two pieces of music in three different listening conditions, according to whether the singers can hear the other participants or not. After analysing all of the individual notes and extracting pitch over time, the authors observed the following regularities: (1) There are transient parts of approximately 120 ms duration at both the beginning and end of a note, where the pitch varies rapidly; (2) the shapes of transient parts differ significantly according to the adjacent pitch, although all singers tend to have a descending transient at the end of a note; (3) the trajectory shapes of female singers differ from those of male singers at the beginnings of notes; (4) between vocal parts, there is a tendency to expand harmonic intervals (by about 8 cents between adjacent voices); (5) the listening condition had no significant effect on within-note pitch trajectories.},
	pages = {1005--1014},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Dai, Jiajie and Dixon, Simon},
	date = {2019-08-01},
	file = {Ingediende versie:D\:\\Lokaal\\Documenten\\Zotero\\storage\\9N8CYY6A\\Dai en Dixon - 2019 - Intonation trajectories within tones in unaccompan.pdf:application/pdf},
}

@online{utrecht_university_human-centered_2023,
	title = {Human-centered Artificial Intelligence - Universiteit Utrecht},
	url = {https://www.uu.nl/onderzoek/human-centered-artificial-intelligence},
	abstract = {Our research will focus on technical innovations in the field of programming intelligence, but also on the social, ethical and human aspects of {AI}.},
	author = {{Utrecht University}},
	urldate = {2023-02-13},
	date = {2023-02-10},
	langid = {dutch},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\Y323GI2Y\\human-centered-artificial-intelligence.html:text/html},
}

@book{burgoyne_cross-validated_2007,
	title = {A Cross-Validated Study of Modelling Strategies for Automatic Chord Recognition in Audio.},
	abstract = {Although automatic chord recognition has generated a number of recent papers in {MIR}, nobody to date has done a proper cross validation of their recognition results. Cross validation is the most common way to establish baseline standards and make comparisons, e.g., for {MIREX} competitions, but a lack of labelled aligned training data has rendered it impractical. In this paper, we present a comparison of several modelling strategies for chord recognition, {hiddenMarkov} models ({HMMs}) and conditional random fields ({CRFs}), on a new set of aligned ground truth for the Beatles data set of Sheh and Ellis (2003). Consistent with previous work, our models use pitch class profile ({PCP}) vectors for audio modelling. Our results show improvement over previous literature, provide precise estimates of the performance of both old and new approaches to the problem, and suggest several avenues for future work.},
	pagetotal = {251},
	author = {Burgoyne, John and Pugin, Laurent and Kereliuk, Corey and Fujinaga, Ichiro},
	date = {2007-01-01},
	note = {Pages: 254},
}

@misc{walshaw_abc2mtex_1997,
	title = {{ABC}2MTEX: An easy way of transcribing folk and traditional music, Version 1.0},
	author = {Walshaw, Chris},
	date = {1997},
	note = {University of Greenwich, London},
}

@article{parncutt_psychocultural_2018,
	title = {A Psychocultural Theory of Musical Interval: Bye Bye Pythagoras},
	volume = {35},
	issn = {0730-7829},
	url = {https://doi.org/10.1525/mp.2018.35.4.475},
	doi = {10.1525/mp.2018.35.4.475},
	shorttitle = {A Psychocultural Theory of Musical Interval},
	abstract = {The Pythagoreans linked musical intervals with integer ratios, cosmic order, and the human soul. The empirical approach of Aristoxenus, based on real musicians making real music, was neglected. Today, many music scholars and researchers still conceptualize intervals as ratios. We argue that this idea is fundamentally incorrect and present convergent evidence against it. There is no internally consistent “Just” scale: a 6th scale degree that is 5:3 above the 1st is not a perfect 5th (3:2) above the 2nd (9:8). Pythagorean tuning solves this problem, but creates another: ratios of psychologically implausible large numbers. Performers do not switch between two ratios of one interval (e.g., 5:4 and 81:64 for the major third), modern studies of performance intonation show no consistent preferences for specific ratios, and no known brain mechanism is sensitive to ratios in musical contexts. Moreover, physical frequency and perceived pitch are not the same. Rameau and Helmholtz derived musical intervals from the harmonic series, which is audible in everyday sounds including voiced speech; but those intervals, like musical intervals, are perceived categorically. Musical intervals and scales, although they depend in part on acoustic factors, are primarily psychocultural entities—not mathematical or physical. Intervals are historically and culturally variable distances that are learned from oral traditions. There is no perfect tuning for any interval; even octaves are stretched relative to 2:1. Twelve-tone equal temperament is not intrinsically better or worse than Just or Pythagorean. Ratio theory is an important chapter in the history Western musical thought, but it is inconsistent with a modern evidence-based understanding of musical structure, perception and cognition.},
	pages = {475--501},
	number = {4},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Parncutt, Richard and Hair, Graham},
	urldate = {2023-04-03},
	date = {2018-04-01},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\HN2NI52C\\Parncutt en Hair - 2018 - A Psychocultural Theory of Musical Interval Bye B.pdf:application/pdf;Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\T6BEVNDA\\A-Psychocultural-Theory-of-Musical-IntervalBye-Bye.html:text/html},
}

@article{van_maanen_interpretation_2021,
	title = {The interpretation of behavior-model correlations in unidentified cognitive models},
	volume = {28},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-020-01783-y},
	doi = {10.3758/s13423-020-01783-y},
	abstract = {The rise of computational modeling in the past decade has led to a substantial increase in the number of papers that report parameter estimates of computational cognitive models. A common application of computational cognitive models is to quantify individual differences in behavior by estimating how these are expressed in differences in parameters. For these inferences to hold, models need to be identified, meaning that one set of parameters is most likely, given the behavior under consideration. For many models, model identification can be achieved up to a scaling constraint, which means that under the assumption that one parameter has a specific value, all remaining parameters are identified. In the current note, we argue that this scaling constraint implies a strong assumption about the cognitive process that the model is intended to explain, and warn against an overinterpretation of the associative relations found in this way. We will illustrate these points using signal detection theory, reinforcement learning models, and the linear ballistic accumulator model, and provide suggestions for a clearer interpretation of modeling results.},
	pages = {374--383},
	number = {2},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {van Maanen, Leendert and Miletić, Steven},
	urldate = {2023-04-03},
	date = {2021-04-01},
	langid = {english},
	keywords = {Decision making, Math modeling, Reinforcement learning, Signal detection theory},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\CCSBH6X3\\van Maanen en Miletić - 2021 - The interpretation of behavior-model correlations .pdf:application/pdf},
}

@misc{midi_manufacturers_association_complete_2014,
	title = {The Complete {MIDI} 1.0 Detailed Specification},
	url = {https://www.midi.org/specifications/midi1-specifications/general-midi-specifications/general-midi-1},
	author = {{MIDI Manufacturers Association}},
	date = {2014},
	file = {complete_midi_96-1-3.pdf:D\:\\Lokaal\\Documenten\\Zotero\\storage\\3V2G8887\\complete_midi_96-1-3.pdf:application/pdf},
}

@misc{dougherty_choral_2004,
	title = {Choral Tuning: A Solution to “The Question of the Supertonic” in Just Intonation},
	author = {Dougherty, Jason Michael},
	date = {2004},
	note = {Master's thesis},
	file = {Dougherty - 2004 - Choral Tuning A Solution to “The Question of the .pdf:D\:\\Lokaal\\Documenten\\Zotero\\storage\\3U9BRGVP\\Dougherty - 2004 - Choral Tuning A Solution to “The Question of the .pdf:application/pdf},
}

@online{dominikschaller_barbershop_2015,
	title = {Barbershop Tags - Ring-a-Ding Ding!},
	url = {https://www.barbershoptags.com/tag-3064-Ring-a-Ding-Ding!},
	author = {{DominikSchaller}},
	urldate = {2023-04-07},
	date = {2015},
	file = {Barbershop Tags - Ring-a-Ding Ding!:D\:\\Lokaal\\Documenten\\Zotero\\storage\\ESCVHYHC\\tag-3064-Ring-a-Ding-Ding!.html:text/html},
}

@article{kopiez_intonation_2003,
	title = {Intonation of Harmonic Intervals: Adaptability of Expert Musicians to Equal Temperament and Just Intonation},
	volume = {20},
	issn = {0730-7829},
	url = {https://online.ucpress.edu/mp/article/20/4/383/62149/Intonation-of-Harmonic-Intervals-Adaptability-of},
	doi = {10.1525/mp.2003.20.4.383},
	shorttitle = {Intonation of Harmonic Intervals},
	abstract = {This study examines the deviation in the intonation of simultaneously sounding tones under the condition of an embedded melody task. Two professional musicians (trumpet players) were chosen as subjects to play the missing upper voice of a four-part audio example, while listening via headphones to the remaining three parts in adaptive five-limit just intonation and equal temperament. The experimental paradigm was that of a controlled varied condition with a 2 (tuning systems) × 5 (interval categories) × 5 (renditions) × 2 (players) factorial design. An analysis of variance showed a nonsignificant difference between the average deviation of harmonic intonation in the two systems used. Mean deviations of 4.9 cents ({SD} = 6.5 cents) in the equal-temperament condition and of 6.7 cents ({SD} = 8.1 cents) in the just-intonation condition were found. Thus, we assume that the musicians employed the same intonation for equaltemperament and just-intonation versions (an unconscious},
	pages = {383--410},
	number = {4},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Kopiez, Reinhard},
	urldate = {2023-04-10},
	date = {2003-06-01},
	langid = {english},
	note = {Publisher: University of California Press},
}

@article{fonville_ben_1991,
	title = {Ben Johnston's Extended Just Intonation: A Guide for Interpreters},
	volume = {29},
	issn = {0031-6016},
	url = {https://www.jstor.org/stable/833435},
	doi = {10.2307/833435},
	shorttitle = {Ben Johnston's Extended Just Intonation},
	pages = {106--137},
	number = {2},
	journaltitle = {Perspectives of New Music},
	author = {Fonville, John},
	urldate = {2023-04-10},
	date = {1991},
	note = {Publisher: Perspectives of New Music},
	file = {JSTOR Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\BQUZPS8H\\Fonville - 1991 - Ben Johnston's Extended Just Intonation A Guide f.pdf:application/pdf},
}

@article{averill_bell_1999,
	title = {Bell Tones and Ringing Chords: Sense and Sensation in Barbershop Harmony},
	volume = {41},
	issn = {0043-8774},
	url = {https://www.jstor.org/stable/41700111},
	shorttitle = {Bell Tones and Ringing Chords},
	abstract = {One of the principal goals of barbershop style harmony is the production of "ringing" chords ("bell tones," "expanded sound"), a harmonic phenomenon resulting from just intonation, a preference for dominant seventh chords, closely voiced chords ("close harmony"), and finely honed hearing/listening faculties, among other factors. This article explores the aesthetics of barbershop singing and aspects of the listening experience, especially expanded sound, and relates them to ideology and worldview, gender relations, class and racial identities, and nostalgia in an attempt to understand how tones and acoustic sensation function at a symbolic level (the connection between sensation and sense).},
	pages = {37--51},
	number = {1},
	journaltitle = {The World of Music},
	author = {Averill, Gage},
	urldate = {2023-04-10},
	date = {1999},
	note = {Publisher: [Florian Noetzel {GmbH} Verlag, {VWB} - Verlag für Wissenschaft und Bildung, Schott Music {GmbH} \& Co. {KG}, Bärenreiter]},
	file = {JSTOR Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\L96T6AES\\Averill - 1999 - Bell Tones and Ringing Chords Sense and Sensation.pdf:application/pdf},
}

@article{boyden_prelleur_1951,
	title = {Prelleur, Geminiani, and Just Intonation},
	volume = {4},
	issn = {0003-0139},
	url = {https://online.ucpress.edu/jams/article/4/3/202/49422/Prelleur-Geminiani-and-Just-Intonation},
	doi = {10.2307/829621},
	pages = {202--219},
	number = {3},
	journaltitle = {Journal of the American Musicological Society},
	shortjournal = {Journal of the American Musicological Society},
	author = {Boyden, David D.},
	urldate = {2023-04-10},
	date = {1951-10-01},
	langid = {english},
	note = {Publisher: University of California Press},
}

@book{forte_tonal_1979,
	edition = {3},
	title = {Tonal Harmony in Concept and Practice},
	isbn = {0-03-020756-8},
	abstract = {A large 3rd, or major 3rd (M3) encompassing four half steps.},
	publisher = {Holt, Rinehart, and Winston},
	author = {Forte, Allen},
	date = {1979},
}

@book{persichetti_twentieth-century_1961,
	edition = {4},
	title = {Twentieth-Century Harmony: Creative Aspects And Practice},
	publisher = {Ww Norton \& Co},
	author = {Persichetti, Vincent},
	date = {1961},
}

@incollection{sethares_adaptive_2005,
	location = {London},
	title = {Adaptive Tunings},
	isbn = {978-1-84628-113-6},
	url = {https://doi.org/10.1007/1-84628-113-X_8},
	pages = {155--178},
	booktitle = {Tuning, Timbre, Spectrum, Scale},
	publisher = {Springer},
	editor = {Sethares, William A.},
	urldate = {2023-04-18},
	date = {2005},
	langid = {english},
	doi = {10.1007/1-84628-113-X_8},
	keywords = {Adaptive Tuning, Musical Context, Pitch Change, Scale Step, Tonal Center},
}

@software{dobroselsky_melanchalldrywetmidi_2023,
	title = {melanchall/drywetmidi},
	rights = {{MIT}},
	url = {https://github.com/melanchall/drywetmidi},
	abstract = {.{NET} library to read, write, process {MIDI} files and to work with {MIDI} devices},
	author = {Dobroselsky, Maxim},
	urldate = {2023-04-19},
	date = {2023-04-14},
	note = {original-date: 2017-03-22T14:35:05Z},
	keywords = {midi, midi-api, midi-device, midi-parser, playback, recording},
}

@misc{uni_global_union_top_2017,
	title = {Top 10 Principles for Ethical {AI}},
	author = {{UNI Global Union}},
	date = {2017},
}

@article{horner_common_1996,
	title = {Common tone adaptive tuning using genetic algorithms},
	volume = {100},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.415887},
	doi = {10.1121/1.415887},
	abstract = {This paper introduces a genetic algorithm method for adaptive tuning of chord sequences. The algorithm retains the tunings of common tones from previous chords, and adjusts the tunings of the other notes. The genetic algorithm method avoids problems associated with simpler enumerative, greedy, and distributive tuning strategies. The paper gives results for several musical examples using several different error measures, with extended results for minimizing the worst tuning error among harmonic thirds and fifths.},
	pages = {630--640},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Horner, Andrew and Ayers, Lydia},
	urldate = {2023-04-21},
	date = {1996-07-01},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\UTP86AGP\\Common-tone-adaptive-tuning-using-genetic.html:text/html},
}

@book{abbott_acoustic_2001,
	title = {Acoustic evaluation and analysis of the female barbershop tenor voice},
	publisher = {The Florida State University},
	author = {Abbott, Susan Elayne},
	date = {2001},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\J3ND9ZFL\\intermediateredirectforezproxy.html:text/html},
}

@article{sundberg_rules_2009,
	title = {Rules for automated performance of ensemble music},
	rights = {Copyright Harwood Academic Publishers {GmbH}},
	issn = {1029-0087},
	url = {https://www.tandfonline.com/doi/abs/10.1080/07494468900640071},
	doi = {10.1080/07494468900640071},
	abstract = {Recently developed parts of a computer program are presented that contain a rule system which automatically converts music scores to musical performance, and which, in a sense, can be regarded as a...},
	journaltitle = {Contemporary Music Review},
	author = {Sundberg, Johan and Friberg, Anders and Frydén, Lars},
	urldate = {2023-04-21},
	date = {2009-08-24},
	langid = {english},
	note = {Publisher: Taylor \& Francis Group},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\377FYSAF\\07494468900640071.html:text/html;Volledige Tekst:D\:\\Lokaal\\Documenten\\Zotero\\storage\\JFSA7JTQ\\Sundberg e.a. - 2009 - Rules for automated performance of ensemble music.pdf:application/pdf},
}

@misc{hsiao_compound_2021,
	title = {Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs},
	url = {http://arxiv.org/abs/2101.02402},
	doi = {10.48550/arXiv.2101.02402},
	shorttitle = {Compound Word Transformer},
	abstract = {To apply neural sequence models such as the Transformers to music generation tasks, one has to represent a piece of music by a sequence of tokens drawn from a finite set of pre-defined vocabulary. Such a vocabulary usually involves tokens of various types. For example, to describe a musical note, one needs separate tokens to indicate the note's pitch, duration, velocity (dynamics), and placement (onset time) along the time grid. While different types of tokens may possess different properties, existing models usually treat them equally, in the same way as modeling words in natural languages. In this paper, we present a conceptually different approach that explicitly takes into account the type of the tokens, such as note types and metric types. And, we propose a new Transformer decoder architecture that uses different feed-forward heads to model tokens of different types. With an expansion-compression trick, we convert a piece of music to a sequence of compound words by grouping neighboring tokens, greatly reducing the length of the token sequences. We show that the resulting model can be viewed as a learner over dynamic directed hypergraphs. And, we employ it to learn to compose expressive Pop piano music of full-song length (involving up to 10K individual tokens per song), both conditionally and unconditionally. Our experiment shows that, compared to state-of-the-art models, the proposed model converges 5--10 times faster at training (i.e., within a day on a single {GPU} with 11 {GB} memory), and with comparable quality in the generated music.},
	number = {{arXiv}:2101.02402},
	publisher = {{arXiv}},
	author = {Hsiao, Wen-Yi and Liu, Jen-Yu and Yeh, Yin-Cheng and Yang, Yi-Hsuan},
	urldate = {2023-04-21},
	date = {2021-01-07},
	eprinttype = {arxiv},
	eprint = {2101.02402 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {arXiv Fulltext PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\Q3ZLMVG9\\Hsiao e.a. - 2021 - Compound Word Transformer Learning to Compose Ful.pdf:application/pdf;arXiv.org Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\7T2AIRX9\\2101.html:text/html},
}

@online{de_haas_music_2012,
	title = {Music information retrieval based on tonal harmony},
	rights = {Open Access (free)},
	url = {https://dspace.library.uu.nl/handle/1874/226713},
	abstract = {With the emergence of large scale digitalisation of music, content-based methods to maintain, structure, and provide access to digital music repositories have become increasingly important. This doctoral dissertation covers a wide range of methods that aim to aid in the organisation of music information. From both a practical as well as cognitive point of view, it is logical to structure musical content by defining similarity relations between documents. Consequently, the notion of music similarity has become a fundamental concept within the area music information retrieval ({MIR}) research. In this dissertation we study a particular type of music similarity: the similarity of musical harmony. Because both musically trained and untrained listeners have extensive knowledge about music, it is rather unlikely that all information needed for sound similarity judgement can be found in the musical information source alone. Therefore, to be able to place chord sequences in the context of Western tonal harmony, we investigate two approaches towards automatic harmony analysis. Although the first generative grammar-based solution yields good results on a small dataset, it exposed some practical challenges that prevented it to be extended to process larger datasets. Hence, the second harmonic analysis solution exploits state-of-the-art functional programming techniques, like type-level computation and error-correcting parsers, to meet these challenges. This model, named {HarmTrace}, is fast, flexible, and returns analyses that are in accordance with harmony theory. We evaluate these harmonic annotations, which explain the role of a chord in its tonal context, both qualitatively as well as quantitatively, and show how they can aid in harmonic similarity estimation and automatic chord transcription. We investigate three novel approaches to harmonic similarity: a geometric, a local alignment, and a common embeddable subtree based approach. The geometric approach, named {TPSD}, uses a music theoretically motivated step functions to assess the similarity of two chord sequences; the common embeddable subtree approach estimates harmonic similarity by matching hierarchical harmonic analysis annotations; and the local alignment solution uses context-aware substitution functions to align sequences of chords. For each of these harmonic similarity solutions, the adjustable parameters are discussed and evaluated. For the evaluation a large new chord sequence corpus is assembled consisting of 5028 different chord sequences, some of which describe the same song. The results show that an alignment approach that uses the {HarmTrace} harmony model performs best in retrieving these similar chord sequences. All proposed similarity measures rely on the availability of sequences of symbolic chord labels. To extend the application domain, we demonstrate how automatic chord transcription from musical audio can be improved by exploiting our model of tonal harmony},
	type = {Dissertation},
	author = {de Haas, W. B.},
	urldate = {2023-04-21},
	date = {2012-02-28},
	langid = {english},
	note = {Accepted: 2012-02-17T08:19:17Z
{ISBN}: 9789039357354
Publisher: Utrecht University},
}

@article{chandna_deep-learning_2022,
	title = {A Deep-Learning Based Framework for Source Separation, Analysis, and Synthesis of Choral Ensembles},
	volume = {2},
	doi = {10.3389/frsip.2022.808594},
	abstract = {Choral singing in the soprano, alto, tenor and bass ({SATB}) format is a widely practiced and studied art form with significant cultural importance. Despite the popularity of the choral setting, it has received little attention in the field of Music Information Retrieval. However, the recent publication of high-quality choral singing datasets as well as recent developments in deep learning based methodologies applied to the field of music and speech processing, have opened new avenues for research in this field. In this paper, we use some of the publicly available choral singing datasets to train and evaluate state-of-the-art source separation algorithms from the speech and music domains for the case of choral singing. Furthermore, we evaluate existing monophonic F0 estimators on the separated unison stems and propose an approximation of the perceived F0 of a unison signal. Additionally, we present a set of applications combining the proposed methodologies, including synthesizing a single singer voice from the unison, and transposing and remixing the separated stems into a synthetic multi-singer choral signal. We finally conduct a set of listening tests to perform a perceptual evaluation of the results we obtain with the proposed methodologies.},
	pages = {808594},
	journaltitle = {Frontiers in Signal Processing},
	shortjournal = {Frontiers in Signal Processing},
	author = {Chandna, Pritish and Cuesta, Helena and Petermann, Darius and Gómez, Emilia},
	date = {2022-04-01},
	file = {Volledige Tekst:D\:\\Lokaal\\Documenten\\Zotero\\storage\\SGXBYRNE\\Chandna e.a. - 2022 - A Deep-Learning Based Framework for Source Separat.pdf:application/pdf},
}

@incollection{burns_7_1999,
	location = {San Diego},
	title = {7 - Intervals, Scales, and Tuning},
	isbn = {978-0-12-213564-4},
	url = {https://www.sciencedirect.com/science/article/pii/B9780122135644500081},
	series = {Cognition and Perception},
	abstract = {The chapter discusses the possible origins and bases of scales including those aspects of scales that are universal across musical cultures. It also addresses the perception of the basic unit of melodies and scales, the musical interval. Natural intervals are define as intervals that show maximum sensory consonance and harmony, have influenced the evolution of the scales of many musical cultures, but the standards of intonation for a given culture are the learned interval categories of the scales of that culture. Based on the results of musical interval adjustment and identification experiments, and on measurements of intonation in performance, the intonation standard for Western music appears to be a version of the equitempered scale that is slightly compressed for small intervals, and stretched for wide intervals, including the octave. The perception of musical intervals shares a number of commonalities with the perception of phonemes in speech, most notably categorical-like perception, and an equivalence of spacing, in sensation units, of categories along the respective continua. However, the perception of melodic musical intervals appears to be the only example of ideal categorical perception in which discrimination is totally dependent on identification. Therefore this chapter concludes that, rather than speech being “special” as ofttimes proclaimed by experimental psychologists it seems that music is truly special.},
	pages = {215--264},
	booktitle = {The Psychology of Music (Second Edition)},
	publisher = {Academic Press},
	author = {Burns, Edward M.},
	editor = {Deutsch, Diana},
	urldate = {2023-04-21},
	date = {1999-01-01},
	langid = {english},
	doi = {10.1016/B978-012213564-4/50008-1},
	file = {ScienceDirect Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\NIMM9MY7\\Burns - 1999 - 7 - Intervals, Scales, and TuningThis chapter is.pdf:application/pdf;ScienceDirect Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\GKGQZJWG\\B9780122135644500081.html:text/html},
}

@article{schwar_differentiable_2021,
	title = {A {DIFFERENTIABLE} {COST} {MEASURE} {FOR} {INTONATION} {PROCESSING} {IN} {POLYPHONIC} {MUSIC}},
	abstract = {Intonation is the process of choosing an appropriate pitch for a given note in a musical performance. Particularly in polyphonic singing, where all musicians can continuously adapt their pitch, this leads to complex interactions. To achieve an overall balanced sound, the musicians dynamically adjust their intonation considering musical, perceptual, and acoustical aspects. When adapting the intonation in a recorded performance, a sound engineer may have to individually ﬁne-tune the pitches of all voices to account for these aspects in a similar way. In this paper, we formulate intonation adaptation as a cost minimization problem. As our main contribution, we introduce a differentiable cost measure by adapting and combining existing principles for measuring intonation. In particular, our measure consists of two terms, representing a tonal aspect (the proximity to a tonal grid) and a harmonic aspect (the perceptual dissonance between salient frequencies). We show that, combining these two aspects, our measure can be used to ﬂexibly account for different artistic intents while allowing for robust and joint processing of multiple voices in real-time. In an experiment, we demonstrate the potential of our approach for the task of intonation adaptation of amateur choral music using recordings from a publicly available multitrack dataset.},
	journaltitle = {Proceedings of the 22nd {ISMIR} Conference},
	author = {Schwär, Simon and Rosenzweig, Sebastian and Müller, Meinard},
	date = {2021},
	langid = {english},
	file = {Schwär e.a. - 2021 - A DIFFERENTIABLE COST MEASURE FOR INTONATION PROCE.pdf:D\:\\Lokaal\\Documenten\\Zotero\\storage\\PSNR54NF\\Schwär e.a. - 2021 - A DIFFERENTIABLE COST MEASURE FOR INTONATION PROCE.pdf:application/pdf},
}

@article{nordmark_intonation_1996,
	title = {Intonation preferences for major thirds with non-beating ensemble sounds},
	abstract = {The frequency ratios, or intervals, of the twelve-tone scale can be mathematically dejned in several slightly diferent ways, each of which may be more or less appropriate in different musical contexts. For maximum mobility in musical key, instruments of our time withfied tuning are typically tuned in equal temperament, except for performances of early music or avant-garde contemporary music. Some contend that pure intonation, being free of beats, is more natural, and would be preferred in instruments with variable tuning. The sound of choirs is such that beats are very unlikely to serve as cues for intonation. Choral performers have access to variable tuning, yet have not been shown to prefer pure intonation. The diference between alternative intonation schemes is largest for the major third interval. Choral directors and other musically expert subjects were asked to adjust to their preference the intonation of 20 major third intervals in synthetic ensemble sounds. The preferred size of the major third was 395.4 cents, with intra- subject averages ranging from 388 to 407 cents.},
	author = {Nordmark, Jan and Ternström, Sten},
	date = {1996-03-01},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\5Z4X4B75\\Nordmark en Ternström - 1996 - Intonation preferences for major thirds with non-b.pdf:application/pdf},
}

@online{dobrian_timing_2014,
	title = {Timing in {MIDI} files {\textbar} Computer Audio and Music Programming – 2014},
	url = {https://sites.uci.edu/camp2014/2014/05/19/timing-in-midi-files/},
	author = {Dobrian, Christopher},
	urldate = {2023-04-21},
	date = {2014-05-19},
	langid = {american},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\92EY7JUP\\timing-in-midi-files.html:text/html},
}

@incollection{pollens_pitch_2022,
	location = {Cambridge},
	title = {Pitch Notation Conventions},
	isbn = {978-1-108-42199-7},
	url = {https://www.cambridge.org/core/books/history-of-stringed-keyboard-instruments/pitch-notation-conventions/BA088BB4AB776A5CF7B6975AAB3DB843},
	pages = {xxi--xxii},
	booktitle = {A History of Stringed Keyboard Instruments},
	publisher = {Cambridge University Press},
	editor = {Pollens, Stewart},
	urldate = {2023-04-21},
	date = {2022},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\ENW3VIM3\\BA088BB4AB776A5CF7B6975AAB3DB843.html:text/html},
}

@online{hua_synthesizer_2020,
	title = {Synthesizer V {\textbar} Dreamtonics},
	url = {https://dreamtonics.com/synthesizerv/},
	titleaddon = {Dreamtonics},
	author = {Hua, K},
	urldate = {2023-04-20},
	date = {2020-04-15},
	langid = {japanese},
	file = {Snapshot:D\:\\Lokaal\\Documenten\\Zotero\\storage\\42QMTSS5\\synthesizerv.html:text/html},
}

@misc{fjeld_principled_2020,
	location = {Rochester, {NY}},
	title = {Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for {AI}},
	url = {https://papers.ssrn.com/abstract=3518482},
	doi = {10.2139/ssrn.3518482},
	shorttitle = {Principled Artificial Intelligence},
	abstract = {The rapid spread of artificial intelligence ({AI}) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these "{AI} principles," there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent {AI} principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of {AI} will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of {AI} toward consensus.},
	number = {3518482},
	author = {Fjeld, Jessica and Achten, Nele and Hilligoss, Hannah and Nagy, Adam and Srikumar, Madhulika},
	urldate = {2023-04-20},
	date = {2020-01-15},
	langid = {english},
	keywords = {Adam Nagy, Hannah Hilligoss, Jessica Fjeld, Madhulika Srikumar, Nele Achten, Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for {AI}, {SSRN}},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\THENH56N\\Fjeld e.a. - 2020 - Principled Artificial Intelligence Mapping Consen.pdf:application/pdf},
}

@article{danaher_automation_2021,
	title = {Automation, work and the achievement gap},
	volume = {1},
	issn = {2730-5961},
	url = {https://doi.org/10.1007/s43681-020-00028-x},
	doi = {10.1007/s43681-020-00028-x},
	abstract = {Rapid advances in {AI}-based automation have led to a number of existential and economic concerns. In particular, as automating technologies develop enhanced competency, they seem to threaten the values associated with meaningful work. In this article, we focus on one such value: the value of achievement. We argue that achievement is a key part of what makes work meaningful and that advances in {AI} and automation give rise to a number achievement gaps in the workplace. This could limit people’s ability to participate in meaningful forms of work. Achievement gaps are interesting, in part, because they are the inverse of the (negative) responsibility gaps already widely discussed in the literature on {AI} ethics. Having described and explained the problem of achievement gaps, the article concludes by identifying four possible policy responses to the problem.},
	pages = {227--237},
	number = {3},
	journaltitle = {{AI} and Ethics},
	shortjournal = {{AI} Ethics},
	author = {Danaher, John and Nyholm, Sven},
	urldate = {2023-04-20},
	date = {2021-08-01},
	langid = {english},
	keywords = {Achievement, Artificial intelligence, Automation, Autonomy, Community, Mastery, Meaningful work, Responsibility gap},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\L3RHB3AP\\Danaher en Nyholm - 2021 - Automation, work and the achievement gap.pdf:application/pdf},
}

@article{braga_emperor_2017,
	title = {The Emperor of Strong {AI} Has No Clothes: Limits to Artificial Intelligence},
	volume = {8},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/8/4/156},
	doi = {10.3390/info8040156},
	shorttitle = {The Emperor of Strong {AI} Has No Clothes},
	abstract = {Making use of the techniques of media ecology we argue that the premise of the technological Singularity based on the notion computers will one day be smarter that their human creators is false. We also analyze the comments of other critics of the Singularity, as well supporters of this notion. The notion of intelligence that advocates of the technological singularity promote does not take into account the full dimension of human intelligence. They treat artificial intelligence as a figure without a ground. Human intelligence as we will show is not based solely on logical operations and computation, but also includes a long list of other characteristics that are unique to humans, which is the ground that supporters of the Singularity ignore. The list includes curiosity, imagination, intuition, emotions, passion, desires, pleasure, aesthetics, joy, purpose, objectives, goals, telos, values, morality, experience, wisdom, judgment, and even humor.},
	pages = {156},
	number = {4},
	journaltitle = {Information},
	author = {Braga, Adriana and Logan, Robert K.},
	urldate = {2023-04-20},
	date = {2017-12},
	langid = {english},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial general intelligence, artificial intelligence, computer, emotion, figure/ground, intelligence, logic, technological Singularity},
	file = {Full Text PDF:D\:\\Lokaal\\Documenten\\Zotero\\storage\\C2MILQCP\\Braga en Logan - 2017 - The Emperor of Strong AI Has No Clothes Limits to.pdf:application/pdf},
}

@article{calo_artificial_2017,
	title = {Artificial Intelligence Policy: A Primer and Roadmap},
	volume = {51},
	url = {https://heinonline.org/HOL/Page?handle=hein.journals/davlr51&id=413&div=&collection=},
	shorttitle = {Artificial Intelligence Policy},
	pages = {399},
	journaltitle = {U.C. Davis Law Review},
	shortjournal = {U.C.D. L. Rev.},
	author = {Calo, Ryan},
	date = {2017},
	file = {Artificial Intelligence Policy\: A Primer and Roadmap Symposium - Future-Proofing Law\: From RDNA to Robots (Part 2) 51 U.C. Davis Law Review 2017-2018:D\:\\Lokaal\\Documenten\\Zotero\\storage\\63TV99Y7\\LandingPage.html:text/html},
}

@article{gottschall_rise_2015,
	title = {The Rise of Storytelling Machines},
	pages = {179--180},
	journaltitle = {What to Think about Machines that Think; Brockman, J., Ed},
	author = {Gottschall, J.},
	date = {2015},
}

@article{searle_minds_1980,
	title = {Minds, brains, and programs},
	volume = {3},
	issn = {1469-1825, 0140-525X},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A},
	doi = {10.1017/S0140525X00005756},
	abstract = {This article can be viewed as an attempt to explore the consequences of two propositions. (1) Intentionality in human beings (and animals) is a product of causal features of the brain. I assume this is an empirical fact about the actual causal relations between mental processes and brains. It says simply that certain brain processes are sufficient for intentionality. (2) Instantiating a computer program is never by itself a sufficient condition of intentionality. The main argument of this paper is directed at establishing this claim. The form of the argument is to show how a human agent could instantiate the program and still not have the relevant intentionality. These two propositions have the following consequences: (3) The explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program. This is a strict logical consequence of 1 and 2. (4) Any mechanism capable of producing intentionality must have causal powers equal to those of the brain. This is meant to be a trivial consequence of 1. (5) Any attempt literally to create intentionality artificially (strong {AI}) could not succeed just by designing programs but would have to duplicate the causal powers of the human brain. This follows from 2 and 4.“Could a machine think?” On the argument advanced here only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong {AI} has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.},
	pages = {417--424},
	number = {3},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Searle, John R.},
	urldate = {2023-04-20},
	date = {1980-09},
	langid = {english},
	note = {Publisher: Cambridge University Press},
	keywords = {artificial intelligence, brain, intentionality, mind},
}

@article{duifhuis_measurement_1982,
	title = {Measurement of pitch in speech: An implementation of Goldstein’s theory of pitch perception},
	volume = {71},
	shorttitle = {Measurement of pitch in speech},
	pages = {1568--1580},
	number = {6},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Duifhuis, Hendrikus and Willems, Lei F. and Sluyter, R. J.},
	date = {1982},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text:D\:\\Lokaal\\Documenten\\Zotero\\storage\\TDFV6ERW\\Duifhuis e.a. - 1982 - Measurement of pitch in speech An implementation .pdf:application/pdf},
}
